{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b78c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "\n",
    "splitter = RecursiveJsonSplitter(max_chunk_size=400, min_chunk_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "281a8cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GM CORE\n",
      "4  SUBSYSTEMS                                                                                 182\n",
      "- Introduction..................................................................................................................183\n",
      "- Victory Points .............................................................................................................184\n",
      "- Influence .....................................................................................................................187\n",
      "- Research.......................................................................................................................190\n",
      "- Chases..........................................................................................................................192\n",
      "- Infiltration....................................................................................................................196\n",
      "- Reputation ..................................................................................................................200\n",
      "- Duels ............................................................................................................................202\n",
      "- Leadership ................................................................................................................204\n",
      "- Hexploration.............................................................................................................206\n",
      "- Vehicles .....................................................................................................................210\n",
      "5 TREASURE TROVE 218\n",
      "<table><tbody><tr><td>Using Items</td><td>219</td></tr><tr><td>Armor & Armaments</td><td>224</td></tr><tr><td>Alchemy</td><td>244</td></tr><tr><td>Materials</td><td>252</td></tr><tr><td>Momentary Magic</td><td>255</td></tr><tr><td>Trappings of Power</td><td>270</td></tr><tr><td>Gems & Art Objects</td><td>298</td></tr><tr><td>Artifacts</td><td>300</td></tr><tr><td>Intelligent Items</td><td>304</td></tr><tr><td>Cursed Items</td><td>306</td></tr><tr><td>Relics</td><td>308</td></tr></tbody></table>\n",
      "TREASURE TABLE                                   320\n",
      "\n",
      "GLOSSARY AND INDEX                               326\n",
      "Summary : This is a digital illustration depicting a vibrant, sunlit coastal city with domed and minaret-topped buildings, viewed from the water as several large sailing ships approach the harbor. The number \"142\" appears in the lower right corner.\n",
      "\n",
      "photo:  \n",
      "Scene Overview : \n",
      "  • Main subject: A fantasy or historical city with prominent domes and minarets, bathed in warm sunlight.\n",
      "  • Setting: Waterfront, with the city in the background and several large sailing ships in the foreground and midground.\n",
      "  • Perspective: View from the water, looking toward the city; ships are sailing toward the city.\n",
      "  • Composition: The city occupies the left and central background, while the sails of a large ship dominate the right foreground.\n",
      "  • Lighting: Warm, golden sunlight illuminates the city, with dramatic clouds in the sky.\n",
      "  • Colour palette: Predominantly pastel hues—pinks, purples, golds, and blues.\n",
      "\n",
      "Technical Details : \n",
      "  • No visible scale bar, magnification, or scientific annotation.\n",
      "  • The number \"142\" is displayed in yellow in the lower right corner.\n",
      "  • No on-image UI elements or text besides the number.\n",
      "\n",
      "Spatial Relationships : \n",
      "  • Foreground: Large, dark sails of a ship on the right edge.\n",
      "  • Midground: Several ships sailing toward the city, creating a sense of depth and movement.\n",
      "  • Background: The cityscape with domes and minarets, set against a partly cloudy sky.\n",
      "  • The city is positioned using the rule of thirds, drawing the viewer's eye to the architectural features.\n",
      "\n",
      "Analysis : \n",
      "  • The image conveys a sense of adventure and arrival, with the ships heading toward a grand, possibly exotic city.\n",
      "  • The lighting and composition emphasize the city's architectural beauty and the dynamic movement of the ships.\n",
      "  • The number \"142\" may indicate a catalog or reference number, but no further context is provided within the image.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# File path for the JSON file\n",
    "file_path = \"data/GM Core/GM_Core_processed.json\"\n",
    "\n",
    "# Load JSON file\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the \"text\" field from each entry\n",
    "text_chunks = [entry[\"text\"] for entry in data if \"text\" in entry]\n",
    "\n",
    "# Print the first few extracted texts to verify\n",
    "print(\"\\n\".join(text_chunks[:5]))  # Displaying only the first few entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dd81f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section taken from community databricks project\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "import re\n",
    "\n",
    "def perform_semantic_chunking(document, chunk_size=500, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    Performs semantic chunking on a document using recursive character splitting \n",
    "    at logical text boundaries.\n",
    "    \n",
    "    Args:\n",
    "        document (str): The text document to process\n",
    "        chunk_size (int): The target size of each chunk in characters\n",
    "        chunk_overlap (int): The number of characters of overlap between chunks\n",
    "        \n",
    "    Returns:\n",
    "        list: The semantically chunked documents with metadata\n",
    "    \"\"\"\n",
    "    # Create the text splitter with semantic separators\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len\n",
    "    )\n",
    "    \n",
    "    # Split the text into semantic chunks\n",
    "    semantic_chunks = text_splitter.split_text(document)\n",
    "    print(f\"Document split into {len(semantic_chunks)} semantic chunks\")\n",
    "    \n",
    "    # Determine section titles for enhanced metadata\n",
    "    section_patterns = [\n",
    "        r'^#+\\s+(.+)$',      # Markdown headers\n",
    "        r'^.+\\n[=\\-]{2,}$',  # Underlined headers\n",
    "        r'^[A-Z\\s]+:$'       # ALL CAPS section titles\n",
    "    ]\n",
    "    \n",
    "    # Convert to Document objects with enhanced metadata\n",
    "    documents = []\n",
    "    current_section = \"Introduction\"\n",
    "    \n",
    "    for i, chunk in enumerate(semantic_chunks):\n",
    "        # Try to identify section title from chunk\n",
    "        chunk_lines = chunk.split('\\n')\n",
    "        for line in chunk_lines:\n",
    "            for pattern in section_patterns:\n",
    "                match = re.match(pattern, line, re.MULTILINE)\n",
    "                if match:\n",
    "                    current_section = match.group(0)\n",
    "                    break\n",
    "        \n",
    "        # Calculate semantic density (ratio of non-stopwords to total words)\n",
    "        words = re.findall(r'\\b\\w+\\b', chunk.lower())\n",
    "        stopwords = ['the', 'and', 'is', 'of', 'to', 'a', 'in', 'that', 'it', 'with', 'as', 'for']\n",
    "        content_words = [w for w in words if w not in stopwords]\n",
    "        semantic_density = len(content_words) / max(1, len(words))\n",
    "        \n",
    "        doc = Document(\n",
    "            page_content=chunk,\n",
    "            metadata={\n",
    "                \"chunk_id\": i,\n",
    "                \"total_chunks\": len(semantic_chunks),\n",
    "                \"chunk_size\": len(chunk),\n",
    "                \"chunk_type\": \"semantic\",\n",
    "                \"section\": current_section,\n",
    "                \"semantic_density\": round(semantic_density, 2)\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1e4641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document split into 6072 semantic chunks\n",
      "Chunk ID: 500, Size: 447\n",
      "Section: # ENDING THE ENCOUNTER\n",
      "Analysis :\n",
      "  • The image conveys a sense of power imbalance, with the demoness clearly overpowering the knight.\n",
      "  • The presence of additional figures in the background suggests an ongoing or escalating conflict.\n",
      "  • The use of contrasting warm and cool colors enhances the drama and highlights the central figures against the icy setting.\n",
      "initiative order and give each PC the option to pursue\n",
      "any one fleeing foe. Each PC can declare one action,\n",
      "Semantic Density: 0.71\n",
      "Chunk ID: 501, Size: 442\n",
      "Section: # ENDING THE ENCOUNTER\n",
      "any one fleeing foe. Each PC can declare one action,\n",
      "spell, or other ability to use to try to keep up. Then,\n",
      "compare the PC's Speed to that of the target, assess how\n",
      "much the pursuer's chosen spell or ability would help,\n",
      "and factor in any abilities the quarry has that would aid\n",
      "escape. If you determine that the pursuer catches up, go\n",
      "back into combat with the original initiative order. If\n",
      "not, the quarry escapes for now.\n",
      "Total Party Kills\n",
      "Semantic Density: 0.77\n",
      "Chunk ID: 502, Size: 460\n",
      "Section: # ENDING THE ENCOUNTER\n",
      "not, the quarry escapes for now.\n",
      "Total Party Kills  \n",
      "Perhaps the most feared of any outcome of a gaming session, a total party kill (TPK) can spell the end of an adventure or campaign. In a TPK, every member of the party dies. Think in advance about how comfortable you are with TPKs and discuss them with the other players. This can provide valuable insights into not only how you should handle one, but also the implied level of lethality the players expect.\n",
      "Semantic Density: 0.75\n",
      "Chunk ID: 503, Size: 481\n",
      "Section: # ENDING THE ENCOUNTER\n",
      "TPKs are rarely unavoidable. Usually it becomes\n",
      "evident at some point during the session—whether to\n",
      "everyone or only to you—that disaster looms. What\n",
      "the players do with this insight is up to them, but you\n",
      "have more control and can take steps to avoid the TPK.\n",
      "For example, perhaps the PCs' foe gets distracted by\n",
      "something, an ally arrives to help the heroes, or the\n",
      "villain captures them instead of slaying them outright.  \n",
      "The simplest path is to just allow a clear escape route\n",
      "Semantic Density: 0.74\n",
      "Chunk ID: 504, Size: 490\n",
      "Section: # ENDING THE ENCOUNTER\n",
      "The simplest path is to just allow a clear escape route  \n",
      "the PCs can take—perhaps with a few characters still  \n",
      "falling along the way. It isn't entirely your responsibility  \n",
      "to defuse the TPK, but offering such opportunities gives  \n",
      "players more say in their characters' fates.\n",
      "Should a TPK occur anyway, the kind of game you're\n",
      "running should influence your approach to the situation.\n",
      "For example, in a relatively story-light campaign\n",
      "centered around dungeon crawling, a TPK is less of a\n",
      "Semantic Density: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Combining all the text chunks into a single document\n",
    "full_doc = \"\\n\".join(text_chunks)\n",
    "\n",
    "# Perform semantic chunking on the full document\n",
    "semantic_documents = perform_semantic_chunking(full_doc)\n",
    "\n",
    "# A little peak at the results\n",
    "index_to_peak = 500\n",
    "for doc in semantic_documents[index_to_peak:index_to_peak+5]:\n",
    "    print(f\"Chunk ID: {doc.metadata['chunk_id']}, Size: {len(doc.page_content)}\")\n",
    "    \n",
    "    # Printing the section title\n",
    "    print(f\"Section: {doc.metadata['section']}\")\n",
    "    \n",
    "    # Printing the content of the document\n",
    "    print(doc.page_content)\n",
    "    \n",
    "    # Printing the semantic density\n",
    "    print(f\"Semantic Density: {doc.metadata['semantic_density']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e81f2",
   "metadata": {},
   "source": [
    "Now that we have chunks, the next step is to create some embeddings. However, something to consider is whether or not the embeddings should contain the repetitive nature of the `Section` headers. Depending on the descriptiveness of the headers, it is permissible to do so. Unfortunately, with the output we currently have, it is not feasible. We will embed purely the chunks as they stand, without including the metadata, such as `Section`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be1b2632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "\n",
    "# List notation for storing documents, metadata is stored separately for use later\n",
    "docs_for_store = [\n",
    "    Document(\n",
    "        page_content=f\"passage: {doc.page_content}\",\n",
    "        metadata={ # Dict of metadata for each document, dropped chunk_type because I don't know what it does\n",
    "            \"section\": doc.metadata[\"section\"],\n",
    "            \"chunk_id\": doc.metadata[\"chunk_id\"],\n",
    "            \"chunk_size\": doc.metadata[\"chunk_size\"],\n",
    "            \"source\":   \"Player Core 2\"\n",
    "        }\n",
    "    )\n",
    "    for doc in semantic_documents\n",
    "]\n",
    "\n",
    "# Embedding step, utilizing the e5 model\n",
    "emb_fn = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/e5-large-v2\",\n",
    "    encode_kwargs={\"normalize_embeddings\": True},   # E5 wants norm=True\n",
    ")\n",
    "\n",
    "# 4️⃣  Persist in Chroma (or your favourite store)\n",
    "vectordb = Chroma.from_documents(docs_for_store, emb_fn, persist_directory=\"chroma_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa830fcc",
   "metadata": {},
   "source": [
    "This is running QA locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9c1e873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/52/pkkzdswd4vv_f_f5lz_pny4m0000gn/T/ipykernel_92817/899141787.py:9: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrievalQA.run(query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tengu have many avian characteristics. Their faces are tipped with sharp beaks, and their scaled forearms and lower legs end in talons. They are rarely more than 5 feet tall and are even lighter than their smaller frames would suggest, as they have hollow bones. A small number of tengu have vestigial wings.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "value = os.getenv('GEMINI_KEY') \n",
    "retrievalQA = RetrievalQA.from_llm(llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", google_api_key=value), retriever=vectordb.as_retriever())\n",
    "query = \"What do Tengus look like?\"\n",
    "retrievalQA.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c703f6bf",
   "metadata": {},
   "source": [
    "Here is persisting a DB using chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b53b3cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/52/pkkzdswd4vv_f_f5lz_pny4m0000gn/T/ipykernel_92817/969374920.py:15: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=\"chroma_db\", embedding_function=emb_fn)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"My API Key Here\"\n",
    "\n",
    "# In a notebook setting, we call persist to ensure embeddings are written to the disk.\n",
    "# As a script, this wouldn't be necessary.\n",
    "\n",
    "# vectordb.persist() # Persist the vector store disk\n",
    "# vectordb = None # Clear the variable to free memory\n",
    "\n",
    "# Load the persisted database from disk, and use it as normal\n",
    "vectordb = Chroma(persist_directory=\"chroma_db\", embedding_function=emb_fn)\n",
    "retrievalQA = RetrievalQA.from_llm(llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", google_api_key=value), retriever=vectordb.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ad50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tengu have many avian characteristics. Their faces are tipped with sharp beaks and their scaled forearms and lower legs end in talons. They are rarely more than 5 feet tall, and they are even lighter than their smaller frames would suggest, as they have hollow bones. A small number of tengu have vestigial wings.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What do Tengus look like?\"\n",
    "retrievalQA.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faf1cbf",
   "metadata": {},
   "source": [
    "Cleanup time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687900a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectordb.delete_collection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chroma_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
